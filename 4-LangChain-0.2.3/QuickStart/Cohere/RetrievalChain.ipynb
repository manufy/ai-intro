{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_cohere import ChatCohere\n",
    "\n",
    "llm = ChatCohere()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/user_guide\")\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_cohere.embeddings import CohereEmbeddings\n",
    "\n",
    "embeddings = CohereEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "documents = text_splitter.split_documents(docs)\n",
    "vector = FAISS.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"Answer the following question based only on the provided context:\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {input}\"\"\")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Langsmith can help with testing by visualizing test results.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "document_chain.invoke({\n",
    "    \"input\": \"how can langsmith help with testing?\",\n",
    "    \"context\": [Document(page_content=\"langsmith can let you visualize test results\")]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "retriever = vector.as_retriever()\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith is a platform that supports LLM application development, monitoring, and testing. It offers a range of features to facilitate testing and improve the performance of LLM applications. \n",
      "\n",
      "- Initial Test Set: LangSmith enables developers to create datasets containing inputs and reference outputs to run tests on their LLM applications. These test cases can be created, uploaded in bulk, or exported from application traces. \n",
      "- Comparison View: LangSmith allows users to compare the performance of different application versions side by side. This helps identify regressions and improvements across multiple revisions of the application. \n",
      "- Playground: The playground environment offers a space for rapid experimentation and testing of different prompts and models. Each playground run is logged and can be used to create test cases or for comparison. \n",
      "- Beta Testing: During beta testing, LangSmith helps collect data on the LLM application's performance in real-world scenarios. It captures user feedback and allows for run annotation, helping to identify areas where the application performs well or poorly. \n",
      "- Capturing Feedback: LangSmith allows users to attach feedback scores to logged traces, helping to identify problematic responses and draw attention to specific runs. \n",
      "- Annotating Traces: Traces can be sent to annotation queues, where subject matter experts or engineers can closely inspect and annotate them according to different criteria. \n",
      "- Adding Runs to a Dataset: LangSmith lets users add runs as examples to datasets, expanding test coverage on real-world scenarios and improving the application's performance. \n",
      "- Online Evaluations and Automations: In production, LangSmith offers online evaluations and automations to process and score production traces in near real-time. \n",
      "- Monitoring and A/B Testing: LangSmith provides monitoring charts to track key metrics over time. It also supports tag and metadata grouping, enabling A/B testing of different application versions. \n",
      "- Automations: This feature allows users to perform actions on traces in near real-time, such as automatically scoring traces, sending them to annotation queues, or adding them to datasets. \n",
      "- Threads: For multi-turn LLM applications, LangSmith provides a threads view that groups traces from a single conversation, making it easier to track and annotate the application's performance across multiple turns. \n",
      "\n",
      "Overall, LangSmith provides a comprehensive set of tools and features to support testing and improve the performance of LLM applications throughout the development lifecycle.\n"
     ]
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"how can langsmith help with testing?\"})\n",
    "print(response[\"answer\"])\n",
    "\n",
    "# LangSmith offers several features that can help with testing:..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-0.2.3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
